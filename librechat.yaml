# OptimismAI - LibreChat configuration
# https://www.librechat.ai/docs/configuration/librechat_yaml

version: 1.2.1
cache: false

# ---- Register LiteLLM (OpenAI-compatible) as a custom endpoint ----
# Your instance: https://litellm-production-157f.up.railway.app/
# OpenAI-compatible base: /v1
endpoints:
  custom:
    - name: "litellm"   # this is the endpoint key you'll use in modelSpecs.preset.endpoint
      baseURL: "https://litellm-production-157f.up.railway.app/v1"
      headers:
        Authorization: "Bearer sk-1gZNsxNTOEmCt25H1Yq0TA"
      # ✅ this drives the “messageicon” across the UI
      iconURL: "/assets/logo.svg"
      models:
        # We expose a single logical "model" id to LibreChat; the shim isn't needed
        # because AnythingLLM speaks OpenAI format here.
        default: ["optimismai"]
      modelDisplayLabel: "OptimismAI"
      titleConvo: true
      titleModel: "optimismai"
# (Optional) per-model icon(s) if you ever add more models
      modelIcons:
      optimismai: "/assets/logo.svg"
# ---- Interface / UI ----
interface:
  customWelcome: "What's On Your Mind {{user_id}}?"
  privacyPolicy:
    externalUrl: "https://optimismai.app/privacy"
    openNewTab: true
  termsOfService:
    externalUrl: "https://optimismai.app/terms"
    openNewTab: true

  # Keep right panel but trim items
  sidePanel: true
  bookmarks: true
  prompts: false
  agents: false

  # hides Agent Builder/Marketplace & artifacts

  # Remove advanced knobs
  modelSelect: false
  parameters: false
  presets: false

  # Disable Code Interpreter button
  runCode: false

  # Keep web search button visible (provider is configured separately if you use it)
  webSearch: true

# ---- File Uploads (multimodal ON) ----
# Remove prior 'disabled: true' rules so uploads are allowed for our endpoint.
# If you need constraints (types/size), add them here per docs; otherwise omit fileConfig entirely.
# fileConfig:
#   endpoints:
#     OptimismAI:
#       # examples:
#       # accept: ["image/*", "application/pdf"]
#       # maxFiles: 5
#       # maxSizeMB: 15

# ---- Lock the experience to a single, preselected model ----
modelSpecs:
  enforce: true
  list:
    - name: "optimismai"
      label: "OptimismAI"
      default: true
      preset:
        endpoint: "litellm"   # must match endpoints.custom[0].name
         model: "gpt-5-mini"   # or another model if that’s your choice
        promptPrefix: "${OPTIMISMAI_PROMPT}"
        temperature: 0.75
        max_tokens: 4096
